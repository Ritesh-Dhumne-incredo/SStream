pipeline {
 Â Â  agent any



 Â Â  environment {
 Â Â Â Â Â Â  // Credentials are loaded securely from Jenkins
 Â Â Â Â Â Â  DATABRICKS_HOST = 'https://dbc-6289de08-cfb9.cloud.databricks.com'
 Â Â Â Â Â Â  DATABRICKS_TOKEN = credentials('DBT')
        JOB_ID = '216873594474493'
        CLUSTER_ID = '2236063f6f28e164'
 Â Â Â Â Â Â  NOTEBOOK_PATH = '/Workspace/Users/hritik.moon@incredotech.com/SStream/SparkStreaming/API_stream'
 Â Â  }



 Â Â  options {
 Â Â Â Â Â Â  timestamps()
 Â Â  }



 Â Â  stages {
 Â Â Â Â Â Â  stage('Checkout Repo') {
 Â Â Â Â Â Â Â Â Â Â  steps {
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  checkout scm
                git branch: 'main',
                    url: 'https://github.com/Hritik-Incredo/SStream.git'
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "âœ… Checked out code from ${env.GIT_URL}"		
 Â Â Â Â Â Â Â Â Â Â  }
 Â Â Â Â Â Â  }



 Â Â Â Â Â Â  stage('Setup Databricks CLI') {
 Â Â Â Â Â Â Â Â Â Â  steps {
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  bat '''
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  python -m venv venv
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  call venv\\Scripts\\activate
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  pip install --upgrade pip
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  pip install databricks-cli jq
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks --version
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "âœ… Databricks CLI installed"
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  '''
 Â Â Â Â Â Â Â Â Â Â  }
 Â Â Â Â Â Â  }



 Â Â Â Â Â Â  stage('Ensure Databricks Job Exists') {
 Â Â Â Â Â Â Â Â Â Â  steps {
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  bat '''
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  call venv\\Scripts\\activate



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "ğŸ” Checking if job '%JOB_NAME%' exists..."
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks jobs list --output JSON > jobs.json



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set FOUND_JOB_ID=
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  for /f "tokens=* delims=" %%a in ('jq -r ".jobs[] | select(.settings.name==\\"%JOB_NAME%\\") | .job_id" jobs.json') do (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set FOUND_JOB_ID=%%a
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  )



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  if defined FOUND_JOB_ID (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "â™»ï¸ Job already exists with ID %FOUND_JOB_ID%. Updating it..."
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo {"new_settings":{"name":"%JOB_NAME%","tasks":[{"task_key":"spark_task","notebook_task":{"notebook_path":"%NOTEBOOK_PATH%"},"existing_cluster_id":"<your-cluster-id>"}]}} > update.json
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks jobs reset --job-id %FOUND_JOB_ID% --json @update.json
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo %FOUND_JOB_ID% > job_id.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ) else (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "ğŸ†• Creating a new Databricks job..."
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo {"name":"%JOB_NAME%","tasks":[{"task_key":"spark_task","notebook_task":{"notebook_path":"%NOTEBOOK_PATH%"},"new_cluster":{"spark_version":"13.3.x-scala2.12","node_type_id":"small","num_workers":1}}]} > create.json
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks jobs create --json @create.json > created.json
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  jq -r ".job_id" created.json > job_id.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  )



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set /p JOB_ID=<job_id.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "âœ… Job ID is %JOB_ID%"
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  '''
 Â Â Â Â Â Â Â Â Â Â  }
 Â Â Â Â Â Â  }



 Â Â Â Â Â Â  stage('Run Databricks Job and Monitor') {
 Â Â Â Â Â Â Â Â Â Â  steps {
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  bat '''
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  call venv\\Scripts\\activate
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set /p JOB_ID=<job_id.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "ğŸš€ Triggering Databricks job %JOB_ID%..."
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks jobs run-now --job-id %JOB_ID% > run.json
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  jq -r ".run_id" run.json > run_id.txt



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set /p RUN_ID=<run_id.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "ğŸ“¡ Monitoring run ID: %RUN_ID%"



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set ATTEMPTS=0
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  :loop
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set /a ATTEMPTS+=1
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks runs get --run-id %RUN_ID% > status.json
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  jq -r ".state.life_cycle_state" status.json > status.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  jq -r ".state.result_state" status.json > result.txt



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set /p STATUS=<status.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  set /p RESULT=<result.txt
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo Run Status: %STATUS% | Result: %RESULT%



 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  if "%STATUS%"=="TERMINATED" (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  if "%RESULT%"=="SUCCESS" (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "âœ… Job succeeded!"
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  goto done
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ) else (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "âŒ Job failed!"
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  databricks runs get-output --run-id %RUN_ID%
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  exit /b 1
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  )
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  )
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  if %ATTEMPTS% GEQ 60 (
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  echo "â° Timeout waiting for job completion"
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  exit /b 2
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  )
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  timeout /t 10 >nul
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  goto loop
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  :done
 Â Â Â Â Â Â Â Â Â Â Â Â Â Â  '''
 Â Â Â Â Â Â Â Â Â Â  }
 Â Â Â Â Â Â  }
 Â Â  }



 Â Â  post {
 Â Â Â Â Â Â  always {
 Â Â Â Â Â Â Â Â Â Â  echo "ğŸ§¾ Pipeline finished."
 Â Â Â Â Â Â  }
 Â Â Â Â Â Â  failure {
 Â Â Â Â Â Â Â Â Â Â  echo "âŒ Pipeline failed. Check logs and Databricks job output."
 Â Â Â Â Â Â  }
 Â Â  }
}
